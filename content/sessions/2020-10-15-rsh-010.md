+++
title = "RSH 10: Reproducibility"
template = "session.html"
[extra]
desc = "How to make research reproducible"
video = "https://www.youtube.com/watch?v=aqzSmQVsVFQ&list=PLpLblYHCzJAB6blBBa0O2BEYadVZV3JYf"
+++

### Icebreaker

What tool/trick you recommend to make your work/research more reproducible?

- Think of your future self, code+take notes so that your future self will understand what you did
- Code with more than one person, joint projects
- Some means to install software libraries needed
- Conda environments!


### Questions

- Does reproducible also mean completely automated? If others have to be able to run the analysis, it feels like that.
    - automation could be bad and not explicitly specify code versions that break an analysis
    - 
- As a reviewer: do you ask for the code? Do you review the code?
  - I reviewed once a data+software paper and told the editor that I can review the code if they give me 2 weeks more... never heard back :)
  - I usually glance at the code. Once found a serious bug.

- ReproHacks:
  - https://twitter.com/reprohack
  - https://reprohack.github.io/reprohack-hq/

- How do tasks to make work reproducible change given the scale of the project? LHC analysis groups won't act like a small group of ecologists.
    - an example: https://www.nature.com/articles/s41567-018-0342-2

- ReproHack is a great idea: journal-club but for github repro's: try to run the so called "reproducible" code shared by the authors of a paper
  - yes!

- To make our research reproducible, do we have to be using notebooks (Rmarkdown, Jupyter, etc)?
    - I personally think the other way around. Full automation (no interaction) -> more r
